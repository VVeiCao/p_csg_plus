{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhk/anaconda3/envs/csg/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pdb\n",
    "from conf.config import GlobalConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = {'None':0, 'Buildings':1, 'Fences':2, 'Other':3, 'Pedestrians':4, 'Pole':5, 'RoadLines':6, 'Roads':7, 'Sidewalks':8, 'Vegetation':9, 'Vehicles':10, 'Walls':11, 'TrafficSigns':12, 'Sky':13, 'Ground': 14, 'Bridge': 15, 'RailTrack': 16, 'GuardRail':17, 'TrafficLight':18, 'Static':19, 'Dynamic':20, 'Water':21, 'Terrain':22}\n",
    "id_obstacle = [4,10]\n",
    "id_road = [3,6,7,27]\n",
    "id_traffic_red_light = [23]\n",
    "config = GlobalConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_pre_processing(image, scale=1, crop=256, shift_x=0, shift_y=0):\n",
    "    return torch.from_numpy(np.array(scale_and_crop_image(Image.open(image), scale=scale, crop=crop, shift_x=shift_x, shift_y=shift_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_pre_processing(seg, scale=1, crop=256, shift_x=0, shift_y=0):\n",
    "    t = np.array(scale_and_crop_seg(Image.open(seg), scale=scale, crop=crop, shift_x=shift_x, shift_y=shift_y))\n",
    "    return torch.from_numpy(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_crop_seg(seg, scale=1, crop=256, shift_x=0, shift_y=0):\n",
    "    \"\"\"\n",
    "    Scale and crop a PIL image, returning a channels-first numpy array.\n",
    "    \"\"\"\n",
    "    # image = Image.open(filename)\n",
    "    (width, height) = (int(seg.width // scale), int(seg.height // scale))\n",
    "    seg_resized = seg.resize((width, height))\n",
    "    seg = np.asarray(seg_resized)\n",
    "    start_x = height//2 - crop//2 + shift_x\n",
    "    start_y = width//2 - crop//2 + shift_y\n",
    "    cropped_seg = seg[start_x:start_x+crop, start_y:start_y+crop]\n",
    "    cropped_seg = cropped_seg\n",
    "    return cropped_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_crop_image(image, scale=1, crop=256, shift_x=0, shift_y=0):\n",
    "    \"\"\"\n",
    "    Scale and crop a PIL image, returning a channels-first numpy array.\n",
    "    \"\"\"\n",
    "    # image = Image.open(filename)\n",
    "    (width, height) = (int(image.width // scale), int(image.height // scale))\n",
    "    im_resized = image.resize((width, height))\n",
    "    image = np.asarray(im_resized)\n",
    "    start_x = height//2 - crop//2 + shift_x\n",
    "    start_y = width//2 - crop//2 + shift_y\n",
    "    cropped_image = image[start_x:start_x+crop, start_y:start_y+crop]\n",
    "    cropped_image = np.transpose(cropped_image, (2,0,1))\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stich_rgb_images(route_dir, filename):\n",
    "    rgb_front_path = os.path.join(route_dir,\"rgb_front\",filename)\n",
    "    rgb_left_path = os.path.join(route_dir,\"rgb_left\",filename)\n",
    "    rgb_right_path = os.path.join(route_dir,\"rgb_right\",filename)\n",
    "\n",
    "    rgb_front = img_pre_processing(rgb_front_path, scale * 1.1, input_resolution)\n",
    "    rgb_left = img_pre_processing(rgb_left_path, scale, input_resolution, shift_y=-55)\n",
    "    rgb_right = img_pre_processing(rgb_right_path, scale * 1.1, input_resolution, shift_y=55)\n",
    "    \n",
    "    rgb_lfr = torch.cat((rgb_left, rgb_front, rgb_right), axis=2)\n",
    "    im = Image.fromarray(rgb_lfr.permute(1, 2, 0).numpy())\n",
    "    lfr_path = os.path.join(route_dir,\"rgb_lfr\")\n",
    "    if not os.path.exists(lfr_path):\n",
    "        os.makedirs(lfr_path)\n",
    "    im.save(os.path.join(lfr_path,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stich_seg_images(route_dir, filename):\n",
    "    seg_front_path = os.path.join(route_dir,\"seg_front\",filename)\n",
    "    seg_left_path = os.path.join(route_dir,\"seg_left\",filename)\n",
    "    seg_right_path = os.path.join(route_dir,\"seg_right\",filename)\n",
    "\n",
    "    seg_front = seg_pre_processing(seg_front_path, scale * 1.1, input_resolution)\n",
    "    seg_left = seg_pre_processing(seg_left_path, scale, input_resolution, shift_y=-55)\n",
    "    seg_right = seg_pre_processing(seg_right_path, scale * 1.1, input_resolution, shift_y=55)\n",
    "    seg_lfr = torch.cat((seg_front, seg_left, seg_right), axis=1)\n",
    "    im = Image.fromarray(seg_lfr.numpy())\n",
    "    lfr_path = os.path.join(route_dir,\"seg_lfr\")\n",
    "    if not os.path.exists(lfr_path):\n",
    "        os.makedirs(lfr_path)\n",
    "    im.save(os.path.join(lfr_path,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_2d_points(xyz, r1, t1_x, t1_y, r2, t2_x, t2_y):\n",
    "    \"\"\"\n",
    "    Build a rotation matrix and take the dot product.\n",
    "    \"\"\"\n",
    "    # z value to 1 for rotation\n",
    "    xy1 = xyz.copy()\n",
    "    xy1[:,2] = 1\n",
    "\n",
    "    c, s = np.cos(r1), np.sin(r1)\n",
    "    r1_to_world = np.matrix([[c, s, t1_x], [-s, c, t1_y], [0, 0, 1]])\n",
    "\n",
    "    # np.dot converts to a matrix, so we explicitly change it back to an array\n",
    "    world = np.asarray(r1_to_world @ xy1.T)\n",
    "\n",
    "    c, s = np.cos(r2), np.sin(r2)\n",
    "    r2_to_world = np.matrix([[c, s, t2_x], [-s, c, t2_y], [0, 0, 1]])\n",
    "    world_to_r2 = np.linalg.inv(r2_to_world)\n",
    "\n",
    "    out = np.asarray(world_to_r2 @ world).T\n",
    "    \n",
    "    # reset z-coordinate\n",
    "    out[:,2] = xyz[:,2]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lidar_to_histogram_features(lidar, crop=256):\n",
    "    \"\"\"\n",
    "    Convert LiDAR point cloud into 2-bin histogram over 256x256 grid\n",
    "    \"\"\"\n",
    "    def splat_points(point_cloud):\n",
    "        # 256 x 256 grid\n",
    "        pixels_per_meter = 8\n",
    "        hist_max_per_pixel = 5\n",
    "        x_meters_max = 16\n",
    "        y_meters_max = 32\n",
    "        xbins = np.linspace(-2*x_meters_max, 2*x_meters_max+1, 2*x_meters_max*pixels_per_meter+1)\n",
    "        ybins = np.linspace(-y_meters_max, 0, y_meters_max*pixels_per_meter+1)\n",
    "        hist = np.histogramdd(point_cloud[...,:2], bins=(xbins, ybins))[0]\n",
    "        hist[hist>hist_max_per_pixel] = hist_max_per_pixel\n",
    "        overhead_splat = hist/hist_max_per_pixel\n",
    "        return overhead_splat\n",
    "\n",
    "    below = lidar[lidar[...,2]<=-2.0]\n",
    "    above = lidar[lidar[...,2]>-2.0]\n",
    "    below_features = splat_points(below)\n",
    "    above_features = splat_points(above)\n",
    "    features = np.stack([below_features, above_features], axis=-1)\n",
    "    features = np.flip(np.transpose(features, (2, 1, 0)), 2).astype(np.float32)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lidar_preprocessing(route_dir, filename):\n",
    "    lidar_path = os.path.join(route_dir,\"lidar\",filename)\n",
    "    lidar_unprocessed = np.load(lidar_path)[...,:3] # lidar: XYZI\n",
    "    lidar_unprocessed[:,1] *= -1\n",
    "    lidar_processed = lidar_to_histogram_features(lidar_unprocessed, crop=256)\n",
    "    path = os.path.join(route_dir,\"lidar_p\")\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    np.save(os.path.join(path,filename), lidar_processed)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_resolution = 256\n",
    "scale = 1.0\n",
    "def stich_images(config):\n",
    "    for sub_root in tqdm(config.train_data, file=sys.stdout):\n",
    "        root_files = os.listdir(sub_root)\n",
    "        routes = [folder for folder in root_files if not os.path.isfile(os.path.join(sub_root,folder))]\n",
    "        for route in routes:\n",
    "            route_dir = os.path.join(sub_root, route)\n",
    "            num = len(os.listdir(route_dir+\"/rgb_front/\"))\n",
    "            for i in range(num):\n",
    "                filename = f\"{str(i).zfill(4)}.png\"\n",
    "                lidar_filename = f\"{str(i).zfill(4)}.npy\"\n",
    "                \n",
    "                stich_rgb_images(route_dir, filename)\n",
    "                stich_seg_images(route_dir, filename)\n",
    "                lidar_preprocessing(route_dir, lidar_filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]torch.Size([256, 256])\n",
      "torch.Size([256, 767])\n",
      "torch.Size([256, 256])\n",
      "torch.Size([256, 767])\n",
      "torch.Size([256, 256])\n",
      "torch.Size([256, 767])\n",
      "torch.Size([256, 256])\n",
      "torch.Size([256, 767])\n",
      "torch.Size([256, 256])\n",
      "torch.Size([256, 767])\n",
      "torch.Size([256, 256])\n",
      "torch.Size([256, 767])\n",
      "torch.Size([256, 256])\n",
      "torch.Size([256, 767])\n",
      "torch.Size([256, 256])\n",
      "torch.Size([256, 767])\n",
      "torch.Size([256, 256])\n",
      "torch.Size([256, 767])\n",
      "  0%|          | 0/14 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/zhk/project/vae/vae/notebooks/stich_images.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m stich_images(config\u001b[39m=\u001b[39;49mconfig)\n",
      "\u001b[1;32m/home/zhk/project/vae/vae/notebooks/stich_images.ipynb Cell 13\u001b[0m in \u001b[0;36mstich_images\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(i)\u001b[39m.\u001b[39mzfill(\u001b[39m4\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m lidar_filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(i)\u001b[39m.\u001b[39mzfill(\u001b[39m4\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m stich_rgb_images(route_dir, filename)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m stich_seg_images(route_dir, filename)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m lidar_preprocessing(route_dir, lidar_filename)\n",
      "\u001b[1;32m/home/zhk/project/vae/vae/notebooks/stich_images.ipynb Cell 13\u001b[0m in \u001b[0;36mstich_rgb_images\u001b[0;34m(route_dir, filename)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m rgb_front \u001b[39m=\u001b[39m img_pre_processing(rgb_front_path, scale \u001b[39m*\u001b[39m \u001b[39m1.1\u001b[39m, input_resolution)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m rgb_left \u001b[39m=\u001b[39m img_pre_processing(rgb_left_path, scale, input_resolution, shift_y\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m55\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m rgb_right \u001b[39m=\u001b[39m img_pre_processing(rgb_right_path, scale \u001b[39m*\u001b[39;49m \u001b[39m1.1\u001b[39;49m, input_resolution, shift_y\u001b[39m=\u001b[39;49m\u001b[39m55\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m rgb_lfr \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((rgb_left, rgb_front, rgb_right), axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m im \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(rgb_lfr\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mnumpy())\n",
      "\u001b[1;32m/home/zhk/project/vae/vae/notebooks/stich_images.ipynb Cell 13\u001b[0m in \u001b[0;36mimg_pre_processing\u001b[0;34m(image, scale, crop, shift_x, shift_y)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimg_pre_processing\u001b[39m(image, scale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, crop\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, shift_x\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, shift_y\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.221.116.81/home/zhk/project/vae/vae/notebooks/stich_images.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39marray(scale_and_crop_image(Image\u001b[39m.\u001b[39;49mopen(image), scale\u001b[39m=\u001b[39mscale, crop\u001b[39m=\u001b[39mcrop, shift_x\u001b[39m=\u001b[39mshift_x, shift_y\u001b[39m=\u001b[39mshift_y)))\n",
      "File \u001b[0;32m~/anaconda3/envs/csg/lib/python3.9/site-packages/PIL/Image.py:3101\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3098\u001b[0m     fp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(fp\u001b[39m.\u001b[39mread())\n\u001b[1;32m   3099\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 3101\u001b[0m prefix \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(\u001b[39m16\u001b[39;49m)\n\u001b[1;32m   3103\u001b[0m preinit()\n\u001b[1;32m   3105\u001b[0m accept_warnings \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stich_images(config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('csg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1ac6cd3370d6cefa6624f40fcc40c96b9f81bafd78f669beabf9e83f4561800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
